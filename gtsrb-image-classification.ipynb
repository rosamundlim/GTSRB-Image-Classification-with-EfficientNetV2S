{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rosamundl/gtsrb-image-classification?scriptVersionId=140914071\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"**Contributed by :** [Rosamund Lim ](https://www.linkedin.com/in/rosamund-lim/)","metadata":{}},{"cell_type":"markdown","source":"# Summary","metadata":{}},{"cell_type":"markdown","source":"**Background:** The German Traffic Sign Benchmark (GTSRB) is a multi-class, single-image classification challenge, read more [here](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign) at the dataset page. \n\n**Dataset:** There are 43 classes in total, and more than over 50,000 images. There are 39209 training examples, 12,630 test examples. \n\n**EDA**: The classes are imbalanced, for instance, there are way more training examples for \"Speed Limit 50 km/h\" than for the \"dangerous curve left\" category. Training images are blurry and many of them are in low light conditions.\n\n**Approach**: i) To address low quality images, increase the contrast of the images, thanks to the suggestion in this article by [Thomas Tracey] (http://medium.com/@thomastracey/recognizing-traffic-signs-with-cnns-23a4ac66f7a7)) ii) To address class imbalance, include class weights in the model fitting process iii) Implement transfer learning using the EfficientNetV2S architecture which touts  faster training speed and better parameter efficiency than previous models ([source](https://arxiv.org/abs/2104.00298)). \n\n**Results**: weighted-averaged F1 score of 99% on validation set. weighted-averaged F1 score of 98% on test set. ","metadata":{}},{"cell_type":"markdown","source":"# Loading Libraries and Class Labels","metadata":{}},{"cell_type":"code","source":"#importing libraries\nimport os\nimport random\nfrom tqdm import tqdm\nfrom typing import List\n\nfrom PIL import Image\nfrom skimage import exposure\n\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report\n\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras import datasets, layers, models\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:40:49.079181Z","iopub.execute_input":"2023-08-21T13:40:49.079636Z","iopub.status.idle":"2023-08-21T13:40:58.939877Z","shell.execute_reply.started":"2023-08-21T13:40:49.079589Z","shell.execute_reply":"2023-08-21T13:40:58.937917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#classes labels represented in dictionary\nclasses = { 0:'Speed limit (20km/h)',\n            1:'Speed limit (30km/h)', \n            2:'Speed limit (50km/h)', \n            3:'Speed limit (60km/h)', \n            4:'Speed limit (70km/h)', \n            5:'Speed limit (80km/h)', \n            6:'End of speed limit (80km/h)', \n            7:'Speed limit (100km/h)', \n            8:'Speed limit (120km/h)', \n            9:'No passing', \n            10:'No passing veh over 3.5 tons', \n            11:'Right-of-way at intersection', \n            12:'Priority road', \n            13:'Yield', \n            14:'Stop', \n            15:'No vehicles', \n            16:'Veh > 3.5 tons prohibited', \n            17:'No entry', \n            18:'General caution', \n            19:'Dangerous curve left', \n            20:'Dangerous curve right', \n            21:'Double curve', \n            22:'Bumpy road', \n            23:'Slippery road', \n            24:'Road narrows on the right', \n            25:'Road work', \n            26:'Traffic signals', \n            27:'Pedestrians', \n            28:'Children crossing', \n            29:'Bicycles crossing', \n            30:'Beware of ice/snow',\n            31:'Wild animals crossing', \n            32:'End speed + passing limits', \n            33:'Turn right ahead', \n            34:'Turn left ahead', \n            35:'Ahead only', \n            36:'Go straight or right', \n            37:'Go straight or left', \n            38:'Keep right', \n            39:'Keep left', \n            40:'Roundabout mandatory', \n            41:'End of no passing', \n            42:'End no passing veh > 3.5 tons'\n          }","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:40:58.942411Z","iopub.execute_input":"2023-08-21T13:40:58.943182Z","iopub.status.idle":"2023-08-21T13:40:58.954257Z","shell.execute_reply.started":"2023-08-21T13:40:58.943145Z","shell.execute_reply":"2023-08-21T13:40:58.953324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring Training Dataset","metadata":{}},{"cell_type":"code","source":"#creating filepath variables \ndirectory = '/kaggle/input/gtsrb-german-traffic-sign'\ntrain_path = os.path.join(directory,'Train')\nmeta_path = os.path.join(directory,'Meta')\ntest_path = os.path.join(directory,'Test')","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:40:58.955597Z","iopub.execute_input":"2023-08-21T13:40:58.956595Z","iopub.status.idle":"2023-08-21T13:40:58.969767Z","shell.execute_reply.started":"2023-08-21T13:40:58.956561Z","shell.execute_reply":"2023-08-21T13:40:58.96871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#observe the distribution of images across classes in the training set\nsubfolders = os.listdir(train_path)\nimage_count = []\nclass_label = []\n\nfor folder in subfolders:\n    #count number of image files in each directory\n    count = len(os.listdir(os.path.join(train_path, folder)))  \n    image_count.append(count)\n    class_label.append(classes[int(folder)])\n\nfrequency_df = pd.DataFrame({'class':class_label,\n                            'frequency': image_count}\n                           ).sort_values(by='frequency')\n\nfrequency_df","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:40:58.971324Z","iopub.execute_input":"2023-08-21T13:40:58.971923Z","iopub.status.idle":"2023-08-21T13:41:02.465078Z","shell.execute_reply.started":"2023-08-21T13:40:58.971873Z","shell.execute_reply":"2023-08-21T13:41:02.463897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see from the dataframe above that the classes in the training set are imbalanced. i.e. there are many more images from the *\"Speed limit (50km/h)\"* category compared to the *\"Dangerous curve left\"* category. We will now visualise the above dataframe with a barchart","metadata":{}},{"cell_type":"code","source":"# Create a bar chart using Seaborn\nsns.barplot(x=frequency_df['class'], y=frequency_df['frequency'])\n\n# Add labels and title\nplt.xlabel('Class')\nplt.xticks(rotation='vertical',fontsize=8)\nplt.ylabel('Frequency')\nplt.title('GTSRB Training Set Class Distribution')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:41:02.468673Z","iopub.execute_input":"2023-08-21T13:41:02.469013Z","iopub.status.idle":"2023-08-21T13:41:03.208634Z","shell.execute_reply.started":"2023-08-21T13:41:02.468984Z","shell.execute_reply":"2023-08-21T13:41:03.207559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we will visualize random images from the training set folder","metadata":{}},{"cell_type":"code","source":"#create function to get all image paths\ndef get_image_paths(filepath: str) -> List[str]:\n    '''takes in filepath and returns a list of filepath of all images'''\n    image_paths = []\n    class_labels = []\n    for root,subfolders,files in os.walk(train_path):\n        for filename in files:\n            image_paths.append(os.path.join(root, filename))\n            class_labels.append(re.findall(r'\\d+',root)[0])\n            \n    return image_paths, class_labels\n\n#unpack the image paths and class labels for training set\ntrain_image_paths, train_labels = get_image_paths(train_path)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:41:03.209863Z","iopub.execute_input":"2023-08-21T13:41:03.210566Z","iopub.status.idle":"2023-08-21T13:41:11.653959Z","shell.execute_reply.started":"2023-08-21T13:41:03.210528Z","shell.execute_reply":"2023-08-21T13:41:11.652916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_draws = 16\nrandom_draws = random.sample(list(range(1,len(train_labels)+1)),16)\n\nplt.figure(figsize=(16,16))\n\nfor i in range(1,17):\n    plt.subplot(4,4,i)\n    random_index = random_draws[i-1]\n    image = imread(train_image_paths[random_index])\n    plt.imshow(image)\n    plt.title(classes[int(train_labels[random_index])])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:41:11.655697Z","iopub.execute_input":"2023-08-21T13:41:11.656511Z","iopub.status.idle":"2023-08-21T13:41:13.420504Z","shell.execute_reply.started":"2023-08-21T13:41:11.656473Z","shell.execute_reply":"2023-08-21T13:41:13.419473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the images into numpy array","metadata":{}},{"cell_type":"code","source":"train_images = []\n\nfor filepath in tqdm(train_image_paths):\n    image = Image.open(filepath)\n    #resize it to 32 by 32 \n    image = image.resize((32,32),Image.LANCZOS) \n    image = np.array(image).astype(np.uint8)\n    #sharpen contrast\n    image = exposure.equalize_adapthist(image, clip_limit=0.1) \n    #rescale back by 255 \n    image = (image * 255).astype(np.uint8)\n    #append the data to images_numpy \n    train_images.append(image)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:41:13.422357Z","iopub.execute_input":"2023-08-21T13:41:13.422754Z","iopub.status.idle":"2023-08-21T13:47:51.549211Z","shell.execute_reply.started":"2023-08-21T13:41:13.422721Z","shell.execute_reply":"2023-08-21T13:47:51.548268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = np.array(train_images)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:47:51.550715Z","iopub.execute_input":"2023-08-21T13:47:51.551319Z","iopub.status.idle":"2023-08-21T13:47:51.633113Z","shell.execute_reply.started":"2023-08-21T13:47:51.551283Z","shell.execute_reply":"2023-08-21T13:47:51.63208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Below, let's sample the images again after preprocessing was done to heighten the contrast of the images**","metadata":{}},{"cell_type":"code","source":"num_draws = 16\nrandom_draws = random.sample(list(range(1,len(train_labels)+1)),16)\n\nplt.figure(figsize=(16,16))\n\nfor i in range(1,17):\n    plt.subplot(4,4,i)\n    random_index = random_draws[i-1]\n    image = train_images[random_index]\n    plt.imshow(image)\n    plt.title(classes[int(train_labels[random_index])])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:47:51.634797Z","iopub.execute_input":"2023-08-21T13:47:51.635196Z","iopub.status.idle":"2023-08-21T13:47:53.212589Z","shell.execute_reply.started":"2023-08-21T13:47:51.63516Z","shell.execute_reply":"2023-08-21T13:47:53.211636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Below, we verify the shape of the train images and labels. Going forth we will split this dataset into the training and validation set.**","metadata":{}},{"cell_type":"code","source":"train_labels = np.array(train_labels)\nprint(\"shape of train_images:\",train_images.shape)\nprint(\"shape of train_labels:\",train_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:47:53.213909Z","iopub.execute_input":"2023-08-21T13:47:53.214946Z","iopub.status.idle":"2023-08-21T13:47:53.236753Z","shell.execute_reply.started":"2023-08-21T13:47:53.214909Z","shell.execute_reply":"2023-08-21T13:47:53.235825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split into training and validation","metadata":{}},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(train_images,train_labels,\n                                                 test_size=0.2,random_state=42,\n                                                 shuffle=True)\n\nprint(\"X_train.shape\", x_train.shape)\nprint(\"X_valid.shape\", x_val.shape)\nprint(\"y_train.shape\", y_train.shape)\nprint(\"y_val.shape\", y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:47:53.238528Z","iopub.execute_input":"2023-08-21T13:47:53.238889Z","iopub.status.idle":"2023-08-21T13:47:53.294075Z","shell.execute_reply.started":"2023-08-21T13:47:53.238855Z","shell.execute_reply":"2023-08-21T13:47:53.293038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#class weights to handle imbalanced dataset\nclass_weights = class_weight.compute_class_weight(\n                                        class_weight = \"balanced\",\n                                        classes = np.unique(y_train),\n                                        y = y_train                                                   \n                                    )\nclass_weights = dict(zip(np.unique(y_train), class_weights))\nclass_weights = {int(label): weight for label, weight in class_weights.items()}\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:47:53.295502Z","iopub.execute_input":"2023-08-21T13:47:53.295909Z","iopub.status.idle":"2023-08-21T13:47:53.33338Z","shell.execute_reply.started":"2023-08-21T13:47:53.295873Z","shell.execute_reply":"2023-08-21T13:47:53.332347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#one hot encode the class labels\ny_train = keras.utils.to_categorical(y_train, 43)\ny_val = keras.utils.to_categorical(y_val,43)\nprint(\"y_train.shape\", y_train.shape)\nprint(\"y_val.shape\", y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:47:53.337965Z","iopub.execute_input":"2023-08-21T13:47:53.33823Z","iopub.status.idle":"2023-08-21T13:47:53.368105Z","shell.execute_reply.started":"2023-08-21T13:47:53.338205Z","shell.execute_reply":"2023-08-21T13:47:53.367052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the Model (EfficientNetV2S + Transfer Learning)","metadata":{}},{"cell_type":"code","source":"#instantiate EfficientNetV2L\nENV2S=tf.keras.applications.EfficientNetV2S(include_top=False,\n                                          weights=\"imagenet\",\n                                          input_shape=(224, 224, 3),\n                                          include_preprocessing=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:47:53.370888Z","iopub.execute_input":"2023-08-21T13:47:53.371515Z","iopub.status.idle":"2023-08-21T13:48:03.14456Z","shell.execute_reply.started":"2023-08-21T13:47:53.371475Z","shell.execute_reply":"2023-08-21T13:48:03.143552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create upsampling layer\nupsampling = tf.keras.layers.UpSampling2D(size=(7,7))\n#create global average layer\nglobal_avg = tf.keras.layers.GlobalAveragePooling2D()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:48:03.146053Z","iopub.execute_input":"2023-08-21T13:48:03.14641Z","iopub.status.idle":"2023-08-21T13:48:03.153001Z","shell.execute_reply.started":"2023-08-21T13:48:03.146376Z","shell.execute_reply":"2023-08-21T13:48:03.151753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#build trainsfer learning model\nmodel = models.Sequential()\nmodel.add(layers.Input(shape=(32,32,3)))\nmodel.add(upsampling)\nmodel.add(ENV2S)\nmodel.add(global_avg)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(1024, activation='relu'))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(43, activation='softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:48:03.154491Z","iopub.execute_input":"2023-08-21T13:48:03.155103Z","iopub.status.idle":"2023-08-21T13:48:04.923497Z","shell.execute_reply.started":"2023-08-21T13:48:03.155069Z","shell.execute_reply":"2023-08-21T13:48:04.922418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define path for saving checkpoint\nsave_path = \"/kaggle/working/best_weights.hdf5\"\n# define checkpoint \ncheckpoint = tf.keras.callbacks.ModelCheckpoint(save_path,\n                                               monitor='val_accuracy',\n                                               verbose=1, save_best_only=True,\n                                               mode=max)\n# define the conditions for early stopping\nearlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\ncallbacks_list = [checkpoint,earlystop]","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:48:04.925269Z","iopub.execute_input":"2023-08-21T13:48:04.926237Z","iopub.status.idle":"2023-08-21T13:48:04.933145Z","shell.execute_reply.started":"2023-08-21T13:48:04.926196Z","shell.execute_reply":"2023-08-21T13:48:04.931911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile the model\nmodel.compile(optimizer='Adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:48:04.934658Z","iopub.execute_input":"2023-08-21T13:48:04.936068Z","iopub.status.idle":"2023-08-21T13:48:04.967733Z","shell.execute_reply.started":"2023-08-21T13:48:04.936031Z","shell.execute_reply":"2023-08-21T13:48:04.966893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train,y_train,\n                    validation_data=(x_val, y_val),\n                    epochs=10, batch_size=16, \n                    class_weight=class_weights,callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:03:21.516298Z","iopub.execute_input":"2023-08-21T15:03:21.516657Z","iopub.status.idle":"2023-08-21T15:49:20.544039Z","shell.execute_reply.started":"2023-08-21T15:03:21.516626Z","shell.execute_reply":"2023-08-21T15:49:20.543106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label = 'validation accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:49:56.39754Z","iopub.execute_input":"2023-08-21T15:49:56.397946Z","iopub.status.idle":"2023-08-21T15:50:44.007668Z","shell.execute_reply.started":"2023-08-21T15:49:56.397908Z","shell.execute_reply":"2023-08-21T15:50:44.006764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"#load the saved model\nmodel.load_weights(save_path)\nloss,acc = model.evaluate(x_val,y_val,verbose=2)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:51:31.940965Z","iopub.execute_input":"2023-08-21T15:51:31.941368Z","iopub.status.idle":"2023-08-21T15:52:01.954785Z","shell.execute_reply.started":"2023-08-21T15:51:31.941335Z","shell.execute_reply":"2023-08-21T15:52:01.953749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#classification report for the Validation Dataset\nval_prob = model.predict(x_val)\n#convert tests labels in single-digits instead of one-hot encoding\ny_val_arg = np.argmax(y_val,axis=1)\nval_predicted_labels = np.argmax(val_prob, axis = 1) #take argmax because the class with the highest probability would be the predicted class\nval_report = classification_report(y_val_arg,val_predicted_labels)\nprint('---')\nprint('Classification report for Validation Dataset:')\nprint(val_report)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:52:05.660218Z","iopub.execute_input":"2023-08-21T15:52:05.660568Z","iopub.status.idle":"2023-08-21T15:52:49.670239Z","shell.execute_reply.started":"2023-08-21T15:52:05.660538Z","shell.execute_reply":"2023-08-21T15:52:49.669071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading test images \ntest = pd.read_csv(directory + '/Test.csv')\n\ntest_labels = test[\"ClassId\"].values\ntest_imgs = test[\"Path\"].values\n\ntest_data =[]\n\nfor img in tqdm(test_imgs):\n    filepath = os.path.join(directory,img)\n    image = Image.open(filepath)\n    #resize it to 32 by 32 \n    image = image.resize((32,32),Image.LANCZOS) \n    image = np.array(image).astype(np.uint8)\n    #sharpen contrast\n    image = exposure.equalize_adapthist(image, clip_limit=0.1) \n    #rescale back by 255 \n    image = (image * 255).astype(np.uint8)\n    #append the data to images_numpy \n    test_data.append(image)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:53:09.616468Z","iopub.execute_input":"2023-08-21T15:53:09.616999Z","iopub.status.idle":"2023-08-21T15:55:36.144352Z","shell.execute_reply.started":"2023-08-21T15:53:09.616949Z","shell.execute_reply":"2023-08-21T15:55:36.143287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert to numpy array and check the shape of the test data\ntest_data = np.array(test_data)\nprint(test_labels.shape)\nprint(test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:55:42.649084Z","iopub.execute_input":"2023-08-21T15:55:42.649434Z","iopub.status.idle":"2023-08-21T15:55:42.683509Z","shell.execute_reply.started":"2023-08-21T15:55:42.649404Z","shell.execute_reply":"2023-08-21T15:55:42.682386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Produce classification report for the Test Dataset\ntest_prob = model.predict(test_data)\ntest_predicted_labels = np.argmax(test_prob, axis = 1) #take argmax because the class with the highest probability would be the predicted class\ntest_report = classification_report(test_labels,test_predicted_labels)\nprint('---')\nprint('Classification report for Test Dataset:')\nprint(test_report)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T15:55:45.948283Z","iopub.execute_input":"2023-08-21T15:55:45.948646Z","iopub.status.idle":"2023-08-21T15:56:30.457586Z","shell.execute_reply.started":"2023-08-21T15:55:45.948615Z","shell.execute_reply":"2023-08-21T15:56:30.45639Z"},"trusted":true},"execution_count":null,"outputs":[]}]}